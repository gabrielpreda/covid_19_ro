{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility for extracting HTML Table \n",
    "\n",
    "This is adapted from [Parsing HTML Tables in Python with BeautifulSoup and pandas](https://srome.github.io/Parsing-HTML-Tables-in-Python-with-BeautifulSoup-and-pandas/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HTMLTableParser:\n",
    "\n",
    "    def parse_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        #print(response)\n",
    "        soup = BeautifulSoup(response.text, 'html')\n",
    "        #print(soup)\n",
    "        return [(self.parse_html_table(table))\\\n",
    "            for table in soup.find_all('table')]  \n",
    "\n",
    "    def parse_html_table(self, table):\n",
    "        #print(\"new table\")\n",
    "        n_columns = 0\n",
    "        n_rows=0\n",
    "        column_names = []\n",
    "\n",
    "        # Find number of rows and columns\n",
    "        # we also find the column titles if we can\n",
    "        for row in table.find_all('tr'):\n",
    "\n",
    "            # Determine the number of rows in the table\n",
    "            td_tags = row.find_all('td')\n",
    "            if len(td_tags) > 0:\n",
    "                n_rows+=1\n",
    "                if n_columns == 0:\n",
    "                    # Set the number of columns for our table\n",
    "                    n_columns = len(td_tags)\n",
    "\n",
    "            # Handle column names if we find them\n",
    "            th_tags = row.find_all('th') \n",
    "            if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                for th in th_tags:\n",
    "                    column_names.append(th.get_text())\n",
    "\n",
    "        df = pd.DataFrame() \n",
    "        try:                    \n",
    "            # Safeguard on Column Titles\n",
    "            if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "                raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "            columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "\n",
    "            #print(n_rows, n_columns)\n",
    "            df = pd.DataFrame(columns = columns,\n",
    "                  index= range(0,n_rows))\n",
    "\n",
    "            row_marker = 0\n",
    "            for row in table.find_all('tr'):\n",
    "                column_marker = 0\n",
    "                columns = row.find_all('td')\n",
    "\n",
    "                for column in columns:\n",
    "                    df.iat[row_marker,column_marker] = column.get_text()\n",
    "                    column_marker += 1\n",
    "                if len(columns) > 0:\n",
    "                    row_marker += 1\n",
    "\n",
    "            # Convert to float if possible\n",
    "            for col in df:\n",
    "                    df[col] = df[col]\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            pass\n",
    "        #df.head(10)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the historical data\n",
    "\n",
    "Keep the historical data.\n",
    "\n",
    "At a later stage, just download the daily new data and add to the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"https://www.mai.gov.ro/informare-covid-19-grupul-de-comunicare-strategica-\"\n",
    "url_data =\\\n",
    "    [('2020-04-02',\"2-aprilie-ora-13-00/\"),\n",
    "     ('2020-04-03',\"3-aprilie-2020-ora-13-00/\"),\n",
    "     ('2020-04-04',\"4-aprilie-2020-ora-13-00/\"),\n",
    "     ('2020-04-05',\"5-aprilie-2020-ora-13-00/\"),\n",
    "     ('2020-04-06',\"6-aprilie-2020-ora-13-00/\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 is out of bounds for axis 0 with size 1\n",
      "Column titles do not match the number of columns\n",
      "(44, 3)\n",
      "index 1 is out of bounds for axis 0 with size 1\n",
      "Column titles do not match the number of columns\n",
      "(44, 3)\n",
      "index 1 is out of bounds for axis 0 with size 1\n",
      "Column titles do not match the number of columns\n",
      "(45, 3)\n",
      "index 1 is out of bounds for axis 0 with size 1\n",
      "Column titles do not match the number of columns\n",
      "(44, 3)\n",
      "index 1 is out of bounds for axis 0 with size 1\n",
      "Column titles do not match the number of columns\n",
      "(44, 3)\n"
     ]
    }
   ],
   "source": [
    "hp = HTMLTableParser()\n",
    "all_data_df = pd.DataFrame()\n",
    "for current_date, current_url in url_data:\n",
    "    compose_url = f\"{url_base}{current_url}\"\n",
    "    tables = hp.parse_url(compose_url)\n",
    "    payload_table = tables[0]\n",
    "    print(payload_table.shape)\n",
    "    payload_table['date'] = current_date\n",
    "    #remove headers & footers\n",
    "    payload_table = payload_table.iloc[1:]\n",
    "    payload_table = payload_table.iloc[:-1]\n",
    "    all_data_df = all_data_df.append(payload_table)\n",
    "all_data_df.columns = ['No', 'County', 'Confirmed', 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((211, 4), Index(['No', 'County', 'Confirmed', 'Date'], dtype='object'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.shape, all_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>County</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.</td>\n",
       "      <td>Alba</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.</td>\n",
       "      <td>Arad</td>\n",
       "      <td>110</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.</td>\n",
       "      <td>Argeș</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.</td>\n",
       "      <td>Bacău</td>\n",
       "      <td>19</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.</td>\n",
       "      <td>Bihor</td>\n",
       "      <td>39</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No County Confirmed        Date\n",
       "1  1.   Alba         9  2020-04-02\n",
       "2  2.   Arad       110  2020-04-02\n",
       "3  3.  Argeș        10  2020-04-02\n",
       "4  4.  Bacău        19  2020-04-02\n",
       "5  5.  Bihor        39  2020-04-02"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alba', 'Arad', 'Argeș', 'Bacău', 'Bihor', 'Bistrița-Năsăud',\n",
       "       'Botoșani', 'Brașov', 'Brăila', 'Buzău', 'Caraș-Severin',\n",
       "       'Călărași', 'Cluj', 'Constanța', 'Covasna', 'Dâmbovița', 'Dolj',\n",
       "       'Galați', 'Giurgiu', 'Gorj', 'Harghita', 'Hunedoara', 'Ialomița',\n",
       "       'Iași', 'Ilfov', 'Maramureș', 'Mehedinți', 'Mureș', 'Neamț', 'Olt',\n",
       "       'Prahova', 'Satu Mare', 'Sălaj', 'Sibiu', 'Suceava', 'Teleorman',\n",
       "       'Timiș', 'Tulcea', 'Vaslui', 'Vâlcea', 'Vrancea', 'Mun. București',\n",
       "       '–'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.County.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['9', '110', '10', '19', '39', '22', '40', '117', '11', '12', '13',\n",
       "       '17', '105', '111', '34', '82', '7', '–', '100', '37', '54', '38',\n",
       "       '107', '8', '27', '16', '6', '701', '98', '60', '505', '24', '44',\n",
       "       '124', '26', '108', '90', '1', '45', '72', '46', '55', '150',\n",
       "       '866', '126', '70', '544', '15', '128', '14', '28', '48', '127',\n",
       "       '29', '121', '101', '23', '123', '50', '81', '64', '42', '57',\n",
       "       '148', '25', '5', '967', '21', '136', '550', '33', '68', '131',\n",
       "       '30', '114', '47', '56', '88', '78', '160', '49', '1.215', '176',\n",
       "       '79', '552', '157', '52', '58', '84', '138', '31', '119', '32',\n",
       "       '3', '63', '87', '89', '1.228', '181', '566'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.Confirmed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05',\n",
       "       '2020-04-06'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.Date.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace '-' in County with 'Not identified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.loc[all_data_df['County']=='–', 'County'] = 'Not identified'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace '-' in Confirmed with '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.loc[all_data_df['Confirmed']=='–', 'Confirmed'] = 0\n",
    "all_data_df['Confirmed'] = all_data_df['Confirmed'].astype(str)\n",
    "all_data_df['Confirmed'] = all_data_df['Confirmed'].apply(lambda x: x.replace(\".\", \"\"))\n",
    "all_data_df['Confirmed'] = all_data_df['Confirmed'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(all_data_df.Confirmed), min(all_data_df.Confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alba', 'Arad', 'Argeș', 'Bacău', 'Bihor', 'Bistrița-Năsăud',\n",
       "       'Botoșani', 'Brașov', 'Brăila', 'Buzău', 'Caraș-Severin',\n",
       "       'Călărași', 'Cluj', 'Constanța', 'Covasna', 'Dâmbovița', 'Dolj',\n",
       "       'Galați', 'Giurgiu', 'Gorj', 'Harghita', 'Hunedoara', 'Ialomița',\n",
       "       'Iași', 'Ilfov', 'Maramureș', 'Mehedinți', 'Mureș', 'Neamț', 'Olt',\n",
       "       'Prahova', 'Satu Mare', 'Sălaj', 'Sibiu', 'Suceava', 'Teleorman',\n",
       "       'Timiș', 'Tulcea', 'Vaslui', 'Vâlcea', 'Vrancea', 'Mun. București',\n",
       "       'Not identified'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.County.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   9,  110,   10,   19,   39,   22,   40,  117,   11,   12,   13,\n",
       "         17,  105,  111,   34,   82,    7,    0,  100,   37,   54,   38,\n",
       "        107,    8,   27,   16,    6,  701,   98,   60,  505,   24,   44,\n",
       "        124,   26,  108,   90,    1,   45,   72,   46,   55,  150,  866,\n",
       "        126,   70,  544,   15,  128,   14,   28,   48,  127,   29,  121,\n",
       "        101,   23,  123,   50,   81,   64,   42,   57,  148,   25,    5,\n",
       "        967,   21,  136,  550,   33,   68,  131,   30,  114,   47,   56,\n",
       "         88,   78,  160,   49, 1215,  176,   79,  552,  157,   52,   58,\n",
       "         84,  138,   31,  119,   32,    3,   63,   87,   89, 1228,  181,\n",
       "        566], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.Confirmed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in all_data_df.Date.unique():\n",
    "    d_df = all_data_df.loc[all_data_df.Date==date]\n",
    "    d_df.to_csv(os.path.join('ro_covid_19_daily_reports', f\"{date}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.to_csv(os.path.join('ro_covid_19_time_series', \"ro_covid_19_time_series.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
